{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e136a35b-7f50-4886-a4a3-89aad4e20d4c",
   "metadata": {},
   "source": [
    "# PyTorch Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e939da33-c0a1-4a1c-b0a9-f7f77af90454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca66640-4fcf-417f-ac6e-47eca078a2a8",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d0ad3-fd58-43d0-adaa-20cfb4a242b9",
   "metadata": {},
   "source": [
    "Tensors are the most basic unit of storing manipulating data in PyTorch. These are n-dimensional vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59fcef0-3950-4e53-8f74-e91872be0e38",
   "metadata": {},
   "source": [
    "Creating a tensor from a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eb5a046-4c67-4dfc-8007-f968ad9708db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.linspace(1, 10, 10))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1380e6-3f44-4d6a-9a42-54f40d599f3d",
   "metadata": {},
   "source": [
    "Random tensors can be created using the `randn` method. \\\n",
    "An example that generates a tensor that contains 10 batches of data, each with 20 datapoints, each data point with 3 features. (Maybe the x,y,z) values from accelerometer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cec1802-851f-4bd1-b57e-fad771a04db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 20, 3)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69332508-59c6-48d4-8879-c8d334869650",
   "metadata": {},
   "source": [
    "We can fill a tensor with inital value using `full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44f5a933-8d6c-44fb-bbb5-53b428cbd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 3])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.full(size=(10, 20, 3), fill_value=1)\n",
    "print(x.shape)\n",
    "print(x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4993877-6597-4659-962f-00745433f305",
   "metadata": {},
   "source": [
    "## GPU and Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1a947-25c6-491e-b292-e9049078dee0",
   "metadata": {},
   "source": [
    "Tensors can be moved to the GPU. \\\n",
    "**Note** - This will fail if the machine you are running this on does not have a CUDA enabled GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d55426b-4f7e-4e17-b47a-f7ba85e760c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m x\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "x = torch.randn((10, 1), device='cuda')\n",
    "x.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b6cf4-81af-48e6-8818-bfc3c63b4ca4",
   "metadata": {},
   "source": [
    "You can also move a tensor after it has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01178519-79e1-4226-996d-59c6c1396748",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 1)\n",
    "x.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285440b-a4e5-4ca5-8e57-ef0031d8bf20",
   "metadata": {},
   "source": [
    "To write code that will work on both CPU and GPU it is often a good practice to initiate a `device` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1ec3e61-2a95-4931-ac06-56c4c8cac458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "x = torch.randn(10,1)\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8a6d8-33bc-4510-ad51-b9007b3c83bd",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf99f51-a030-43a1-acc7-5e24cda00c8b",
   "metadata": {},
   "source": [
    "At the core of training neural networks is SGD (Stochastic gradient descent). SGD computes partial derivates on the equation created by the loss function with respect to each learnable parameter. This is computed using the chain rule. \\\n",
    "In order to facilitate this, operations on tensors are represented as a DAG (directed acyclic graph) if gradient is enabled for these tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e3e00-28b4-4b84-867e-4423913c3cb3",
   "metadata": {},
   "source": [
    "Learn more about automatic differentition using `autograd` here - https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6499b-c14d-4b5a-9d91-f53d7adaba17",
   "metadata": {},
   "source": [
    "Let us take a look at this by simulating what neural layer might do. \\\n",
    "A simple neural network hidden layer can be defined using \\\n",
    "x : Input vector \\\n",
    "W : Learnable weights \\\n",
    "B : bias or regularization parameter \\\n",
    "y : the output \n",
    "\n",
    "We can then define the operation performed in this simple layers as \\\n",
    "$Y = xW + B$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed755b2c-738c-4a00-9403-7685ee3fe2da",
   "metadata": {},
   "source": [
    "Because we want the tensors representing $W$ and $B$ to have trainable parameters, we will ask pytorch to track the operations performed on them using a DAG by setting the `require_grad` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b8b3506-2e3a-4526-9188-9dadd54fbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "\"\"\"\n",
    "Remember matrix multiplication? x and W are both matrix. \n",
    "So if the dimensions of x is (1x5) and the output is (1x3) then the dimension of the weight\n",
    "matrix W needs to be (5x3)\n",
    "\"\"\"\n",
    "W = torch.randn(5, 3, requires_grad=True)\n",
    "B = torch.randn(3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69c18af8-162e-4368-aff3-8d14f090e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0416,  0.3248,  0.7654],\n",
      "        [ 0.4105,  1.8604, -0.8947],\n",
      "        [ 1.1354,  2.4903, -1.5443],\n",
      "        [ 0.8963, -1.6701,  1.2917],\n",
      "        [ 0.9105, -0.0292, -0.3431]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7ac7f-01d3-4c63-9803-d677605e077a",
   "metadata": {},
   "source": [
    "We can see that W has gradient tracking enabled. Any tensor that uses this in its operation will also inherrit gradient tracking. \\\n",
    "Let us now perform the $xW$ using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4dca313-8a64-45b7-8947-88d2c31ef0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.0089, -1.1907,  3.0813], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "Y = torch.matmul(x, W)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d49d70-0751-4deb-87b3-e1ef63f3befa",
   "metadata": {},
   "source": [
    "We can see that this operation has added a function to the tensor. Let us now perform our addition operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f50cb6f-e32d-48ce-8e22-384a16466bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.0948, -1.1965,  3.9432], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Y = Y + B\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0e231-13b9-4892-9e36-f1b1d828e32d",
   "metadata": {},
   "source": [
    "We can see the addition operation has been recorded as function in the DAG as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559153f2-22fe-4e45-92ab-8f352067d2b8",
   "metadata": {},
   "source": [
    "We can define a simple loss function as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ff03a25-81ab-4581-98b4-edb6f36fda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93ddbbb0-982b-4069-bd4e-f391c89c220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(Y, y) # pass the true and predicted values to the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ed74567-3995-41dd-80f9-028a4ed163a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2495, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb76110e-83cf-4b0d-b8da-a1228ad02350",
   "metadata": {},
   "source": [
    "We can see that the operations performed by the loss function adds another function to the grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1034eec5-97b7-4bea-80f2-bf28cd121efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# The initial gradients are None. We need to do a backward pass to first calculate the gradients.\n",
    "print(W.grad)\n",
    "print(x.grad) # This does not error, even though x does not have requires_grad enabled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae74fc1-626a-4816-b93a-53b8dfeae8c7",
   "metadata": {},
   "source": [
    "We can now calculate the derivates with respect to each of the learnable parameters as - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a64381bd-009e-4088-8b19-12b4f97e4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58d624-d0f6-4e42-8417-8e778e66637f",
   "metadata": {},
   "source": [
    "We can only calculate the gradients ones. Trying to run this again will give an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "940ddd77-4aaa-4c40-ad86-dba8f6a9f557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326cae7-6ace-4957-b365-3ec7815bbcf5",
   "metadata": {},
   "source": [
    "We can view the gradients now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "75474dee-4fef-460f-8ee2-915826ece2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7299, -0.7977,  2.6288],\n",
      "        [ 2.7299, -0.7977,  2.6288],\n",
      "        [ 2.7299, -0.7977,  2.6288],\n",
      "        [ 2.7299, -0.7977,  2.6288],\n",
      "        [ 2.7299, -0.7977,  2.6288]])\n"
     ]
    }
   ],
   "source": [
    "print(W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "face1292-d9f9-450c-b509-529d089b53a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.7299, -0.7977,  2.6288])\n"
     ]
    }
   ],
   "source": [
    "print(B.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a5fa7-986d-4841-8310-7d4a7c24f238",
   "metadata": {},
   "source": [
    "## Linear Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4ac48-3e88-4133-b560-9da4024b4e2d",
   "metadata": {},
   "source": [
    "A linear layer is one of the most basic layers in PyTorch. \\\n",
    "Documentation - https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dd36f27c-5703-4629-a408-4429b2c19141",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 10)\n",
    "linear = torch.nn.Linear(10, 1)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "90e06759-23a6-404f-988e-19255c4b128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3906, -0.7349, -0.8838, -0.1558,  0.2673]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b55b1-2f1a-4f95-be74-a353ad23e73e",
   "metadata": {},
   "source": [
    "## LSTM Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea9411-92c6-4702-b6d6-6b9e25b8af60",
   "metadata": {},
   "source": [
    "Long short term memory layer. \\\n",
    "Documentation - https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9a91b84-ba6f-45a8-b993-1fad7fc1a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 30, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a5aa4-94ee-4433-b35e-a713d4f5549c",
   "metadata": {},
   "source": [
    "If we were using this in a deep network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8c5c3a16-7563-4975-a720-9c91d06f40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM = torch.nn.LSTM(1, 16, 1)  \n",
    "Linear = torch.nn.Linear(16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5d69063d-98df-47eb-a9d3-3539de49fffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 30, 16])\n",
      "torch.Size([5, 30, 1])\n"
     ]
    }
   ],
   "source": [
    "out, (hn, cn) = LSTM(x)\n",
    "Y = Linear(out)\n",
    "print(out.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96e177-6adc-47b0-b768-f7f2208430d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
